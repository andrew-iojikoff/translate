# Построение гистограмм в Python: NumPy, Matplotlib, Pandas & Seaborn

Из этого руководства вы получите знания, которые позволят вам делать качественные, готовые к презентации графики гистограмм в Python с различными вариантами представлений и другими возможностями.

Если у вас есть начальные знания о программировании в Python, а также в области математической статистики, то вы можете использовать эту статью как универсальный справочник для расчета и визуализации гистограмм в Python, используя библиотеки из научного стека, такие как *NumPy*, *Matplotlib*, *Pandas* и *Seaborn*.

Гистограмма - отличный инструмент для быстрой оценки распределения вероятностей, который интуитивно понятен любой компетентной аудитории. Python предлагает несколько различных вариантов расчета и построения гистограмм. Большинство людей знают гистограмму по ее графическому представлению, которое похоже на столбцевую диаграмму:

!!! рисунок

Эта статья поможет вам создать графики, подобные приведенным выше, а также более сложные. Вот что мы рассмотрим в этом руководстве:

- Создание гистограмм в чистом Python без использования сторонних библиотек;
- Расчет	 гистограмм с помощью *NumPy*, обрабатывая данные непосредственно;
- Построение рассчитанной гистограммы с помощью *Matplotlib*, *Pandas* и *Seaborn*


## Гистограммы на чистом Python

Когда вы готовитесь к построению гистограммы, проще всего не думать об составе данных, необходимо просто рассчитать, сколько раз появляется каждое значение в заданном наборе данных (таблица частот). Такой тип данных как словарь [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) в Python хорошо подходит для задачи хранения полученных результатов:

	>>> # Need not be sorted, necessarily
	>>> a = (0, 1, 1, 1, 2, 3, 7, 7, 23)
	
	>>> def count_elements(seq) -> dict:
	...     """Tally elements from `seq`."""
	...     hist = {}
	...     for i in seq:
	...         hist[i] = hist.get(i, 0) + 1
	...     return hist
	
	>>> counted = count_elements(a)
	>>> counted
	{0: 1, 1: 3, 2: 1, 3: 1, 7: 2, 23: 1}

функция *count_elements()* возвращает словарь с уникальными элементами из последовательности *seq* в качестве ключей и соответствующих им частот (количество появлений в последовательности), как соответствующих этим ключам значениям. Перебираем в цикле последовательность *seq*, инструкция означает *hist[i] = hist.get(i, 0) + 1* для каждого элемента из входной последовательности увеличить на единицу значение рассчитываемой гистограммы *hist* с соответствующим ключом.
Фактически, это именно то, что делается с использованием класса *collections.Counter* из стандартной библиотеки, который является подклассом [subclasses](https://github.com/python/cpython/blob/7f1bcda9bc3c04100cb047373732db0eba00e581/Lib/collections/__init__.py#L466) словаря Python и переопределяет его метод *.update()*:

	>>> from collections import Counter
	
	>>> recounted = Counter(a)
	>>> recounted
	Counter({0: 1, 1: 3, 3: 1, 2: 1, 7: 2, 23: 1})


Вы можете видеть, что ваша функция *count_elements* делает практически то же самое, что и collections.Counter, проверим эквивалентность двух последовательностей:

	>>> recounted.items() == counted.items()
	True

> **Техническая справка**: Преобразование с использованием *count_elements()* может быть по умолчанию оптимизировано с помощью Си-функции [C function](https://github.com/python/cpython/blob/a5c42284e69fb309bdd17ee8c1c120d1be383012/Modules/_collectionsmodule.c#L2250) если это возможно использовать. Код Python внутри функции *count_elements()* можно оптимизировать следующим образом: объявить переменную *get = hist.get* перед циклом. Это свяжет метод с переменной для более быстрых вызовов внутри цикла.
Вам может быть полезно создать такие упрощенные функции самим, как первый шаг к пониманию более сложных. Давайте еще еще раз изобретем с гистограммой в виде символов ASCII, которая использует возможности Python по форматированному выводу данных [output formatting](https://docs.python.org/tutorial/inputoutput.html#fancier-output-formatting): 

	def ascii_histogram(seq) -> None:
	    """A horizontal frequency-table/histogram plot."""
	    counted = count_elements(seq)
	    for k in sorted(counted):
	        print('{0:5d} {1}'.format(k, '+' * counted[k]))

Эта функция создает отсортированную частотную диаграмму, в которой значения рассчитанных частот гистограммы представлены в виде соответствующего числа символов плюс (+). Вызов функции *sorted()* для словаря (рассчитанной гистограммы) возвращает отсортированный по его ключам список. Также вы можете создать несколько больший набор данных с помощью модуля Python *random*: 

	>>> # No NumPy ... yet
	>>> import random
	>>> random.seed(1)
	
	>>> vals = [1, 3, 4, 6, 8, 9, 10]
	>>> # Each number in `vals` will occur between 5 and 15 times.
	>>> freq = (random.randint(5, 15) for _ in vals)
	
	>>> data = []
	>>> for f, v in zip(freq, vals):
	...     data.extend([v] * f)
	
	>>> ascii_histogram(data)
	    1 +++++++
	    3 ++++++++++++++
	    4 ++++++
	    6 +++++++++
	    8 ++++++
	    9 ++++++++++++
	   10 ++++++++++++

> **Примечение**: метод [random.seed()](https://docs.python.org/library/random.html#random.seed) используется для инициации и инициализации генератора псевдослучайных чисел [PRNG](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) являющегося основой используемого модуля *random*. Это может звучать как оксюморон, но это метод сделает случайные данные воспроизводимыми и детерминированными. То есть, если вы скопируете весь наш код как есть, вы должны получить точно такую ​​же гистограмму, потому что первый вызов *random.randint()* после инициализации генератора будет генерировать идентичные «случайные» данные с использованием [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister).


## Создание базы: вычислением гистограммы используя NumPy

До сих пор вы работали над тем, что лучше всего назвать «таблицами частот». Но математически гистограмма представляет собой отображение частот на интервалы значений. Технически это может быть использовано для аппроксимации функции плотности вероятности [PDF](https://en.wikipedia.org/wiki/Probability_density_function) случайной величины.
Переходя от «таблицы частот» к настоящей гистограмме берут диапазон значений, а затем подсчитывают количество значений, которые попадают в этот интервал. Это то, что делает функция для гистограмм *histogram()* из NumPy, и она является основой для других функций, с которыми вы ознакомитесь здесь ниже в таких библиотеках Python, как Matplotlib и Pandas.

Рассмотрим набор чисел в формате *float* (вещественных чисел с плавающей запятой), со случайным распределением Лапласа [Laplace distribution](https://en.wikipedia.org/wiki/Laplace_distribution). Кривая плотности вероятности этого распределения имеет более пологие скаты, чем нормального распределения, и имеет два описательных параметра (сдвиг и масштаб):

	>>> import numpy as np
	>>> # `numpy.random` uses its own PRNG.
	>>> np.random.seed(444)
	>>> np.set_printoptions(precision=3)
	
	>>> d = np.random.laplace(loc=15, scale=3, size=500)
	>>> d[:5]
	array([18.406, 18.087, 16.004, 16.221,  7.358])

В этом случае вы работаете с непрерывным распределением, и было бы не очень рационально рассчитывать значение частоты для каждого значения *float* отдельно, вплоть до десятизначного знака после запятой. Вместо этого вы можете загружать данные и подсчитывать результаты наблюдений, которые попадают в каждый интервал. Гистограмма - это результат подсчета количества значений внутри каждого интервала:

	>>> hist, bin_edges = np.histogram(d)
	
	>>> hist
	array([ 1,  0,  3,  4,  4, 10, 13,  9,  2,  4])
	
	>>> bin_edges
	array([ 3.217,  5.199,  7.181,  9.163, 11.145, 13.127, 15.109, 17.091,
	       19.073, 21.055, 23.037])

Этот результат может быть не сразу интуитивно понятен. [np.histogram()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html) по умолчанию использует 10 одинаковых диапазонов значений и возвращает кортеж счетчиков частоты и соответствующих им концов диапазона. Они являются концами интервалов в том смысле, что их на один больше, чем число диапазонов значений рассчитанной гистограммы:

	>>> hist.size, bin_edges.size
	(10, 11)

> **Техническая справка**: Все рассчитанные интервалы данных, кроме последнего (самого правого), полуоткрыты. То есть все интервалы, кроме последнего [включительно, исключительно], являются открытыми [включительно, включительно].

Очень сжатая разбивка на интервалы построенная с помощью NumPy, выглядит так:

	>>> # The leftmost and rightmost bin edges
	>>> first_edge, last_edge = a.min(), a.max()
	
	>>> n_equal_bins = 10  # NumPy's default
	>>> bin_edges = np.linspace(start=first_edge, stop=last_edge,
	...                         num=n_equal_bins + 1, endpoint=True)
	...
	>>> bin_edges
	array([ 0. ,  2.3,  4.6,  6.9,  9.2, 11.5, 13.8, 16.1, 18.4, 20.7, 23. ])

Вышеприведенный случай имеет следующий смысл: 10 одинаково разнесенных в диапазоне от минимального (0) до максимального значения (23) интервалов с шириной 2,3.
Полученные данные передаются в функцию [np.bincount()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html) или [np.searchsorted()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.searchsorted.html). Функция *np.bincount()* сама может быть использована для создания «таблицы частот» с тем отличием, что значение с нулевым вхождением также включено по умолчанию:

	>>> bcounts = np.bincount(a)
	>>> hist, _ = np.histogram(a, range=(0, a.max()), bins=a.max() + 1)
	
	>>> np.array_equal(hist, bcounts)
	True
	
	>>> # Reproducing `collections.Counter`
	>>> dict(zip(np.unique(a), bcounts[bcounts.nonzero()]))
	{0: 1, 1: 3, 2: 1, 3: 1, 7: 2, 23: 1}

> **Примечение**: *hist* по умолчанию использует диапазоны шириной 1.0, а не «дискретные» отсчеты произвольной ширины. Следовательно, это работает только для подсчета вхождений целых чисел, а не для действительных чисел с плавающей точкой *float*, таких как [3.9, 4.1, 4.15].

## Визуализация гистограмм с помощью Matplotlib и Pandas

Теперь, когда вы рассмотрели, как построить гистограмму на чистом Python с нуля, давайте посмотрим, как другие пакеты Python могут выполнить эту работу за нас. [Matplotlib](https://realpython.com/python-matplotlib-guide/) обеспечивает обширную функциональность для визуализации гистограмм из коробки с гибкой оболочкой вокруг гистограмм рассчитанных с помощью *NumPy*:

	import matplotlib.pyplot as plt
	
	# An "interface" to matplotlib.axes.Axes.hist() method
	n, bins, patches = plt.hist(x=d, bins='auto', color='#0504aa',
	                            alpha=0.7, rwidth=0.85)
	plt.grid(axis='y', alpha=0.75)
	plt.xlabel('Value')
	plt.ylabel('Frequency')
	plt.title('My Very Own Histogram')
	plt.text(23, 45, r'$\mu=15, b=3$')
	maxfreq = n.max()
	# Set a clean upper y-axis limit.
	plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)


!! рисунок

Как было определено ранее, для построения графика гистограммы используются рассчитанные заранее интервалы значений с заданными границами по оси *X*, и соответствующие им частоты по оси *Y*. При построении приведенного выше графика значение именованного аргумента *bins = 'auto'*, что определяет выбор между двумя алгоритмами для оценки "идеального" количества интервалов для разбиения всего диапазона значений. В общем смысле целью выбранного алгоритма является определение ширины интервала, которая позволит наиболее точно представить выходные данные. Для получения дополнительной технической информации по этому вопросу, ознакомьтесь со статьей [Выбор интервалов гистограмм (Choosing Histogram Bins) ](http://docs.astropy.org/en/stable/visualization/histogram.html) из документации к *Astropy*. 

Рассмотрим научный стек библиотек Python. Расчет гистограмм производится функцией из библиотеки Pandas *Series.histogram()*, для построения графика гистограммы используется функция [matplotlib.pyplot.hist()](https://github.com/pandas-dev/pandas/blob/cbec58eacd8e9cd94b7f42351b8de4559c250909/pandas/plotting/_core.py#L1310) из библиотеки Matplotlib:

	import pandas as pd
	
	# Generate data on commute times.
	size, scale = 1000, 10
	commutes = pd.Series(np.random.gamma(scale, size=size) ** 1.5)
	
	commutes.plot.hist(grid=True, bins=20, rwidth=0.9,
	                   color='#607c8e')
	plt.title('Commute Times for 1,000 Commuters')
	plt.xlabel('Counts')
	plt.ylabel('Commute Time')
	plt.grid(axis='y', alpha=0.75)

*pandas.DataFrame.histogram()* аналогичен, но создает гистограмму для каждого столбца данных из DataFrame.

## Вычисление оценки плотности ядра (KDE)
В этом уроке мы работали с выборками данных, называемыми статистическими. Независимо от того, являются ли эти данные дискретными или непрерывными, предполагается, что они получены из выборки, которая достоверно имеет статистическое распределение, точно описываемое несколькими параметрами.
Оценка плотности ядра (KDE) является способом оценки функции плотности вероятности (PDF) случайной величины, которая лежит в основе нашей выборки данных. KDE применяется для сглаживания данных.
Используя библиотеку Pandas, вы можете создавать и накладывать друг на друга графики плотности вероятности, используя функцию *plot.kde()*, которая доступна для объектов *Series* и *DataFrame*. Но сначала давайте сгенерируем две разных выборки данных для сравнения:

	>>> # Sample from two different normal distributions
	>>> means = 10, 20
	>>> stdevs = 4, 2
	>>> dist = pd.DataFrame(
	...     np.random.normal(loc=means, scale=stdevs, size=(1000, 2)),
	...     columns=['a', 'b'])
	>>> dist.agg(['min', 'max', 'mean', 'std']).round(decimals=2)
	          a      b
	min   -1.57  12.46
	max   25.32  26.44
	mean  10.12  19.94
	std    3.94   1.94

Теперь, чтобы построим каждую гистограмму в той же системе координат, используя Matplotlib:

	fig, ax = plt.subplots()
	dist.plot.kde(ax=ax, legend=False, title='Histogram: A vs. B')
	dist.plot.hist(density=True, ax=ax)
	ax.set_ylabel('Probability')
	ax.grid(axis='y')
	ax.set_facecolor('#d8dcd6')

!!! рисунок

Эти методы используют [gaussian_kde()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html) из библиотеки SciPy, что приводит к получению более плавного вида плотности вероятности распределения случайной величины (PDF). Если вы более подробно рассмотрите эту функцию, вы можете увидеть, насколько точно она аппроксимирует «истинную» плотность вероятности (PDF) для относительно небольшой выборки из 1000 отсчетов данных. Далее вы можете сначала построить «аналитическое» распределение с помощью *scipy.stats.norm()*. Это экземпляр класса, который инкапсулирует стандартное нормальное распределение, его моменты и другие описывающие функции. Его плотность вероятности (PDF) является «точным» в том смысле, что он определен точно выражением *norm.pdf (x) = exp (-x ** 2/2) / sqrt (2 * pi)*.
Используя это вы можете получить случайную выборку из 1000 отсчетов данных с помощью этой библиотеки, а затем попытаться произвести оценку плотности вероятности (PDF) с помощью метода *scipy.stats.gaussian_kde()*:

	from scipy import stats
	
	# An object representing the "frozen" analytical distribution
	# Defaults to the standard normal distribution, N~(0, 1)
	dist = stats.norm()
	
	# Draw random samples from the population you built above.
	# This is just a sample, so the mean and std. deviation should
	# be close to (1, 0).
	samp = dist.rvs(size=1000)
	
	# `ppf()`: percent point function (inverse of cdf — percentiles).
	x = np.linspace(start=stats.norm.ppf(0.01),
	                stop=stats.norm.ppf(0.99), num=250)
	gkde = stats.gaussian_kde(dataset=samp)
	
	# `gkde.evaluate()` estimates the PDF itself.
	fig, ax = plt.subplots()
	ax.plot(x, dist.pdf(x), linestyle='solid', c='red', lw=3,
	        alpha=0.8, label='Analytical (True) PDF')
	ax.plot(x, gkde.evaluate(x), linestyle='dashed', c='black', lw=2,
	        label='PDF Estimated via KDE')
	ax.legend(loc='best', frameon=False)
	ax.set_title('Analytical vs. Estimated PDF')
	ax.set_ylabel('Probability')
	ax.text(-2., 0.35, r'$f(x) = \frac{\exp(-x^2/2)}{\sqrt{2*\pi}}$',
	        fontsize=12)


!!! рисунок

Это большой фрагмент кода, поэтому давайте затратим немного времени, для того чтобы более подробно рассмотреть несколько ключевых моментов:

- Статистический пакет библиотеки SciPy позволяет создавать объекты Python, представляющие собой аналитические распределения случайной величины различных видов, которые вы можете использовать для создания отсчетов данных. Таким образом *dist = stats.norm ()* представляет непрерывную случайную величину распределенную по нормальному закону, и вы можете генерировать случайные числа с помощью метода *dist.rvs()*.
- Для оценки как аналитической плотности вероятности (PDF), так и гауссовской оценки плотности ядра (KDE) нам нужен массив *х* [квантилей](https://ru.wikipedia.org/wiki/%D0%9A%D0%B2%D0%B0%D0%BD%D1%82%D0%B8%D0%BB%D1%8C) (значение математического ожидания для нормального распределения плюс/минус величина соответствующяя среднеквадратическому отклонению). *stats.gaussian_kde()* предоставляет оценку плотности распределения вероятности (PDF), которую вам необходимо получить при обработке массива входных данных для нашего примера. 

- Последняя строка содержит выражение [LaTex](https://matplotlib.org/users/usetex.html) для вывода математических формул, который прекрасно сочетается с Matplotlib.


## Яркая альтернатива с Seaborn

Давайте добавим еще один пакет Python в наш микс. У Seaborn есть функция *displot()*, которая строит график гистограммы и KDE для одномерного распределения за один шаг. Используя массив NumPy *d* из примера ранее:

	import seaborn as sns
	
	sns.set_style('darkgrid')
	sns.distplot(d)

!!! рисонок

Вызов указанной выше функции производит оценку плотности ядра (KDE). Существует также возможность задать вид закона распределения данных. Это отличается от оценки плотности ядра (KDE) и состоит из параметров для оценки общих данных и указания конкретного вида распределения:

	sns.distplot(d, fit=stats.laplace, kde=False)

!!! рисунок

Еще раз отметим небольшую разницу. В первом случае мы оцениваете неизвестную плотность распределения вероятности (PDF), во втором, мы принимаем данные с известным распределением и находим, какие параметры лучше всего описывают его, учитывая эмпирические данные.

## Другие инструменты в Pandas

В дополнение к рассмотренным инструментам построения графиков, Pandas также предлагает удобный метод *.value_counts()*, который вычисляет гистограмму ненулевых значений в *Series* Pandas:

	>>> import pandas as pd
	
	>>> data = np.random.choice(np.arange(10), size=10000,
	...                         p=np.linspace(1, 11, 10) / 60)
	>>> s = pd.Series(data)
	
	>>> s.value_counts()
	9    1831
	8    1624
	7    1423
	6    1323
	5    1089
	4     888
	3     770
	2     535
	1     347
	0     170
	dtype: int64
	
	>>> s.value_counts(normalize=True).head()
	9    0.1831
	8    0.1624
	7    0.1423
	6    0.1323
	5    0.1089
	dtype: float64

Так же метод *pandas.cut()* является удобным способом для значений разбиения входных данных на произвольные интервалы. Допустим, у вас есть данные о возрасте людей и вы хотите их рационально отобрать их часть:

	>>> ages = pd.Series(
	...     [1, 1, 3, 5, 8, 10, 12, 15, 18, 18, 19, 20, 25, 30, 40, 51, 52])
	>>> bins = (0, 10, 13, 18, 21, np.inf)  # The edges
	>>> labels = ('child', 'preteen', 'teen', 'military_age', 'adult')
	>>> groups = pd.cut(ages, bins=bins, labels=labels)
	
	>>> groups.value_counts()
	child           6
	adult           5
	teen            3
	military_age    2
	preteen         1
	dtype: int64
	
	>>> pd.concat((ages, groups), axis=1).rename(columns={0: 'age', 1: 'group'})
	    age         group
	0     1         child
	1     1         child
	2     3         child
	3     5         child
	4     8         child
	5    10         child
	6    12       preteen
	7    15          teen
	8    18          teen
	9    18          teen
	10   19  military_age
	11   20  military_age
	12   25         adult
	13   30         adult
	14   40         adult
	15   51         adult
	16   52         adult

Приятно, что обе эти операции в конечном счете используют код [Cython](https://github.com/pandas-dev/pandas/tree/master/pandas/_libs), который делает их конкурентоспособными по скорости, сохраняя при этом их гибкость.

## Хорошо, так что я должен использовать?

На данный момент мы рассмотрели на выбор больше, чем несколько функций и методов  для построения гистограмм в Python. Как их можно сравнить? Короче говоря, среди них нет универсальных. Ниже приведен список функций и методов, которые мы рассмотрели в этой статье, все они связаны с их возможностями по разбивке диапазона входных данных и представлением распределений в Python:

|  Имеем/хотим | Преимущества использования | Замечания  |
|---|---|---|
|Чистые целочисленные данные, размещенные в структурах данных Python, таких как список, кортеж или множество. И вы хотите создать гистограмму Python без импорта каких-либо сторонних библиотек.|[collections.Counter()](https://docs.python.org/3.6/library/collections.html#collections.Counter) из стандартной библиотеки Python предлагает быстрый и простой способ получить таблицу частот из контейнера данных.|Это таблица частот, и поэтому она не предполагает использования концепции гистограмм в полном объеме|
|Имеется большой массив данных, и вы хотите вычислить гистограмму, представляющую собой интервалы значений и соответствующие им частоты|Методы Numpy [np.histogram()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html) и [np.bincount()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html) полезны как для вычисления значений гистограммы численно, так и соответствующих интервалов для разбиения диапазона значений.|Для получения дополнительной информации ознакомьтесь с [np.digitize()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.digitize.html).|
|Табличные данные, запакованные в объекте Pandas *Series* или *DataFrame*.|Такие методы Pandas как [Series.plot.hist()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.plot.hist.html), [DataFrame.plot.hist()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.hist.html), [Series.value_counts()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html) и [cut()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html), а также [Series.plot.kde()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.plot.kde.html) и [DataFrame.plot.kde()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.kde.html)|Ознакомьтесь с [документацией Pandas для визуализации данных](https://pandas.pydata.org/pandas-docs/stable/visualization.html) для вдохновения.|
|Создать красивый график с с большим числом гибких настроек из любой структуры данных.|[pyplot.hist()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html) - широко используемая функция для построения гистограмм, которая использует метод *np.histogram()* и является основной функций построения графиков гистограмм в Pandas.|Matplotlib, представляет собой объектно-ориентированный фреймвок, который отлично подходит для тонкой настройки отдельных частей графика гистограммы. Изучение его интерфейса может занять определенное время для того чтобы полностью освоить его. Но в конечном итоге это позволит вам быть предельно точным в том, как в последствии будет выглядеть визуализация ваших данных.|
|Предварительно законченный дизайн и интеграция.|Метод Seaborn [distplot()](https://seaborn.pydata.org/generated/seaborn.distplot.html) для объединения в один графиков гистограммы и расчитанной плотности ядра (KDE) или построения графика распределения случайной величины.|По сути, это «обертка вокруг обертки», которая использует рассчитанную гистограмму Matplotlib, которая, в свою очередь, использует NumPy.|

Удачи в расчете и построении графиков гистограмм в реальных проектах.

